{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the Models Used in the Binary Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Overview\n",
    "\n",
    "## About\n",
    "This notebook provides a more detailed example of how someone might generate and compare an assortment of models for their fairnes and performance.\n",
    "\n",
    "For this test, only \"in-processing\" fairness-aware approaches were considered.\n",
    "\n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "[Part 1](#part1) - Data and Analysis\n",
    "\n",
    "[Part 2](#part2) - Length of Stay Models \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.1](#part2.1) - Out-of-the-Box Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.2](#part2.2) - AIF360 Fairness-Aware (In-Process) Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.3](#part2.3) - Fairlearn Fairness-Aware (In-Process) Models\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[Part 2.4](#part2.4) - Other Methods\n",
    "\n",
    "[Part 3](#part3) - Comparing Models\n",
    "    Includes the fairMLHealth model comparison tool, as well as an example of the Fairlearn Dashboard.\n",
    "\n",
    "[Part 4](#part4) - Save Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fairmlhealth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ea8b794de454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Verify that additonal required packages are present (packages will be loaded later in the notebook)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfairmlhealth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_tutorial_requirements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_supplemental_requirements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvalidate_tutorial_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvalidate_supplemental_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fairmlhealth'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verify that additonal required packages are present (packages will be loaded later in the notebook)\n",
    "from fairmlhealth.__validation import validate_tutorial_requirements, validate_supplemental_requirements\n",
    "validate_tutorial_requirements()\n",
    "validate_supplemental_requirements()\n",
    "\n",
    "# Custom imports\n",
    "from fairmlhealth.__mimic_data import load_mimic3_example, feature_table\n",
    "from fairmlhealth import measure, report\n",
    "\n",
    "# Standard imports\n",
    "from IPython.display import Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sk_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom AIF360 Measurement <a id=\"custom_aif\"></a>\n",
    "As the fairness-mitigating algorithms available in AIF360 require use of the library's custom data object, the KenSci team developed a custom, AIF360-specific function that outputs a fairness comparison table similar to the one available in fairMLHealth.measure. This function was heavily based in code available in the AIF360 tool itself, and is defined in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "def aif_dataset_measures(dataset, models):\n",
    "    \"\"\" Returns a dataframe containing fairness measures for regression \n",
    "            models based on the AIF360 library\n",
    "        Note: function is based heavily on test_thresholds function from\n",
    "            the AIF360 tutorial\n",
    "    \n",
    "    \"\"\"\n",
    "    if not isinstance(models, (list, dict)):\n",
    "        models = [models]\n",
    "    if not isinstance(models, dict):\n",
    "        models = {f'model_{i}': m for i,m in enumerate(models)}\n",
    "    \n",
    "    #\n",
    "    sens_ind = 0\n",
    "    sens_attr = dataset.protected_attribute_names[sens_ind]\n",
    "    unprivileged_groups = [{sens_attr: v} for v in\n",
    "                       dataset.unprivileged_protected_attributes[sens_ind]]\n",
    "    privileged_groups = [{sens_attr: v} for v in\n",
    "                     dataset.privileged_protected_attributes[sens_ind]]\n",
    "    #\n",
    "    metric_dict = defaultdict(list)\n",
    "    for name, model in models.items():\n",
    "        y_pred = model.predict(dataset).labels\n",
    "        dataset_pred = dataset.copy()\n",
    "        dataset_pred.labels = y_pred\n",
    "        metric = ClassificationMetric(\n",
    "                    dataset, dataset_pred,\n",
    "                    unprivileged_groups =unprivileged_groups,\n",
    "                    privileged_groups =privileged_groups)\n",
    "        \n",
    "        metric_dict['Disparate Impact Ratio'].append(\n",
    "            metric.disparate_impact())\n",
    "        metric_dict['Statistical Parity Difference'].append(\n",
    "            metric.statistical_parity_difference())\n",
    "        metric_dict['Average Odds Difference'].append(\n",
    "            metric.average_odds_difference())\n",
    "        metric_dict['Equal Opportunity Difference'].append(\n",
    "            metric.equal_opportunity_difference())\n",
    "        metric_dict['Balanced Accuracy Difference'].append(\n",
    "            (metric.true_positive_rate() + metric.true_negative_rate()) / 2)\n",
    "        metric_dict['Between-Group Coefficient of Variation'].append(\n",
    "            metric.between_group_coefficient_of_variation())\n",
    "        metric_dict['Theil Index'].append(\n",
    "            metric.theil_index())\n",
    "    \n",
    "    results = pd.DataFrame().from_dict(metric_dict).transpose()\n",
    "    results.columns = models.keys()\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Checker\n",
    "\n",
    "Below we define a simple timer so that we can display compute times for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def check_time(start_time = None):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        start_time (datetime object, optional): If not None, check_time \n",
    "            returns the difference between start_time and the current \n",
    "            datetime. Otherwise, check_time returns the current datetime. \n",
    "            Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        A datetime object.  \n",
    "    \"\"\"\n",
    "    if start_time is not None:\n",
    "        elapsed_time = datetime.datetime.now() - start_time\n",
    "        rprt = f\"{elapsed_time} (hr:mn:sc)\"\n",
    "        return rprt\n",
    "        return elapsed_time\n",
    "    else:\n",
    "        return datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "# Part 1 - Data and Analysis <a class = \"anchor\" id = \"part1\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# path_to_mimic_data_folder = \"[path to your downloaded data folder]\"\n",
    "path_to_mimic_data_folder = pd.read_csv(\"ProtectedAttributes_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Subset <a id=\"datasubset\"></a>\n",
    "All features other than age are one-hot encoded and prefixed with their variable type (e.g. \"GENDER_\", \"ETHNICITY_\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This data subset has 22434 total observations and 648 input features \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw Feature</th>\n",
       "      <th>Category Count (Encoded Features)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIAGNOSIS</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ETHNICITY</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENDER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INSURANCE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LANGUAGE</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MARRIED</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PROCEDURE</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RELIGION</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Raw Feature  Category Count (Encoded Features)\n",
       "0         AGE                                  1\n",
       "1   DIAGNOSIS                                282\n",
       "2   ETHNICITY                                 41\n",
       "3      GENDER                                  1\n",
       "4   INSURANCE                                  5\n",
       "5    LANGUAGE                                 69\n",
       "6     MARRIED                                  7\n",
       "7   PROCEDURE                                222\n",
       "8    RELIGION                                 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMIT_ID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE</th>\n",
       "      <th>ETHNICITY_ASIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - ASIAN INDIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CAMBODIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CHINESE</th>\n",
       "      <th>ETHNICITY_ASIAN - FILIPINO</th>\n",
       "      <th>...</th>\n",
       "      <th>PROCEDURE_CCS_222</th>\n",
       "      <th>PROCEDURE_CCS_223</th>\n",
       "      <th>PROCEDURE_CCS_224</th>\n",
       "      <th>PROCEDURE_CCS_225</th>\n",
       "      <th>PROCEDURE_CCS_226</th>\n",
       "      <th>PROCEDURE_CCS_227</th>\n",
       "      <th>PROCEDURE_CCS_228</th>\n",
       "      <th>PROCEDURE_CCS_229</th>\n",
       "      <th>PROCEDURE_CCS_231</th>\n",
       "      <th>length_of_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1074323</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.144444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1061231</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.496528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1033329</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.768056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1106669</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.988889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1071577</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.364583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 650 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADMIT_ID   AGE  GENDER_M  ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE  \\\n",
       "0   1074323  65.0         0                                        0   \n",
       "1   1061231  70.0         1                                        0   \n",
       "2   1033329  75.0         1                                        0   \n",
       "5   1106669  70.0         1                                        0   \n",
       "7   1071577  75.0         1                                        0   \n",
       "\n",
       "   ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "5                                                  0                    \n",
       "7                                                  0                    \n",
       "\n",
       "   ETHNICITY_ASIAN  ETHNICITY_ASIAN - ASIAN INDIAN  \\\n",
       "0                0                               0   \n",
       "1                0                               0   \n",
       "2                0                               0   \n",
       "5                0                               0   \n",
       "7                0                               0   \n",
       "\n",
       "   ETHNICITY_ASIAN - CAMBODIAN  ETHNICITY_ASIAN - CHINESE  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "5                            0                          0   \n",
       "7                            0                          0   \n",
       "\n",
       "   ETHNICITY_ASIAN - FILIPINO  ...  PROCEDURE_CCS_222  PROCEDURE_CCS_223  \\\n",
       "0                           0  ...                  0                  0   \n",
       "1                           0  ...                  1                  0   \n",
       "2                           0  ...                  0                  0   \n",
       "5                           0  ...                  0                  0   \n",
       "7                           0  ...                  1                  0   \n",
       "\n",
       "   PROCEDURE_CCS_224  PROCEDURE_CCS_225  PROCEDURE_CCS_226  PROCEDURE_CCS_227  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "5                  0                  0                  0                  1   \n",
       "7                  0                  0                  0                  1   \n",
       "\n",
       "   PROCEDURE_CCS_228  PROCEDURE_CCS_229  PROCEDURE_CCS_231  length_of_stay  \n",
       "0                  0                  0                  0        1.144444  \n",
       "1                  0                  0                  0        5.496528  \n",
       "2                  0                  0                  0        6.768056  \n",
       "5                  0                  0                  0        6.988889  \n",
       "7                  0                  0                  0        5.364583  \n",
       "\n",
       "[5 rows x 650 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data and keep a 10K observation subset to speed processing\n",
    "df = load_mimic3_example(path_to_mimic_data_folder) \n",
    "df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "# Subset to ages 65+\n",
    "df = df.loc[df['AGE'].ge(65), :]\n",
    "df.drop('GENDER_F', axis=1, inplace=True) # Redundant with GENDER_M\n",
    "\n",
    "# Display insights\n",
    "display(feature_table(df))\n",
    "display(Markdown('---'))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a binary target flagging whether an observation's length_of_stay value is above or below the mean. \n",
    "# mean_val = df['length_of_stay'].mean()\n",
    "# df['long_los'] = df['length_of_stay'].apply(lambda x: 1 if x > mean_val else 0)\n",
    "# los_tbl = df[['length_of_stay', 'long_los']].describe().transpose().round(4)\n",
    "# display(los_tbl)\n",
    "\n",
    "# # Display LOS distributions\n",
    "# display(Markdown('---'))\n",
    "# ax = df['length_of_stay'].plot(kind='kde', title=\"Probability Density of Length of Stay\")\n",
    "# ax.set_xlabel(\"Length of Stay in Days\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Subset and Split Data\n",
    "X = df.loc[:, [c for c in df.columns if c not in ['ADMIT_ID','length_of_stay', 'long_los']]]\n",
    "y = df.loc[:, ['long_los']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15030, 648) (15030, 1) (7404, 648) (7404, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "# Part 2 -  <a class = \"anchor\" id = \"part2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "targs = ['LOS > mean', 'LOS <= mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores for Random Sampling: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.61      0.61      0.61     13730\n",
      " LOS <= mean       0.39      0.39      0.39      8704\n",
      "\n",
      "    accuracy                           0.52     22434\n",
      "   macro avg       0.50      0.50      0.50     22434\n",
      "weighted avg       0.52      0.52      0.52     22434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# generate \"predictions\" as random sample of target values\n",
    "y = df['long_los']\n",
    "pos_weight = y.mean()\n",
    "weights = [1-pos_weight, pos_weight]\n",
    "values = list(set(y))\n",
    "y_pred_baseline = np.array(random.choices(values, weights, k=df.shape[0]))\n",
    "y_prob_baseline = y_pred_baseline\n",
    "\n",
    "# display baseline performance \n",
    "print(\"\\n\", \"Prediction Scores for Random Sampling:\", \"\\n\",\n",
    "          sk_metric.classification_report(y, y_pred_baseline, target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Part 2.1 - Out-of-the-Box Models <a class = \"anchor\" id = \"part2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.399715 (hr:mn:sc)\n",
      "\n",
      " Naive Bayes Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.76      0.85      0.80      4531\n",
      " LOS <= mean       0.71      0.58      0.64      2873\n",
      "\n",
      "    accuracy                           0.75      7404\n",
      "   macro avg       0.74      0.72      0.72      7404\n",
      "weighted avg       0.74      0.75      0.74      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_params = {'alpha': 20, 'fit_prior': True}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_time()\n",
    "nb_model = BernoulliNB(**nb_params)\n",
    "nb_model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Naive Bayes Prediction Scores:\", \"\\n\", \n",
    "          sk_metric.classification_report(y_test, y_pred_nb, target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.485999 (hr:mn:sc)\n",
      "\n",
      " Decision Tree Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.74      0.85      0.79      4531\n",
      " LOS <= mean       0.69      0.52      0.59      2873\n",
      "\n",
      "    accuracy                           0.72      7404\n",
      "   macro avg       0.71      0.68      0.69      7404\n",
      "weighted avg       0.72      0.72      0.71      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_params = {'min_samples_split': 10, 'min_samples_leaf': 2,\n",
    "             'max_depth': 10, 'criterion': 'entropy'}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_time()\n",
    "dt_model = DecisionTreeClassifier(**dt_params)\n",
    "dt_model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Decision Tree Prediction Scores:\", \"\\n\", \n",
    "          sk_metric.classification_report(y_test, y_pred_dt, target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:02:39.408150 (hr:mn:sc)\n",
      "\n",
      " Random Forest Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.77      0.90      0.83      4531\n",
      " LOS <= mean       0.78      0.57      0.66      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.77      0.73      0.74      7404\n",
      "weighted avg       0.77      0.77      0.76      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_params = {'criterion': 'entropy', 'n_estimators': 1800, \n",
    "             'min_samples_split': 5, 'bootstrap': False}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_time()\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Random Forest Prediction Scores:\", \"\\n\", \n",
    "          sk_metric.classification_report(y_test, y_pred_rf, target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:21.273132 (hr:mn:sc)\n",
      "\n",
      " Logit Regression Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.79      0.87      0.83      4531\n",
      " LOS <= mean       0.75      0.63      0.69      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.77      0.75      0.76      7404\n",
      "weighted avg       0.77      0.78      0.77      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_params = {'penalty': \"none\", 'max_iter': 10**4}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_time()\n",
    "lr_model = LogisticRegression(**lr_params)\n",
    "lr_model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Logit Regression Prediction Scores:\", \"\\n\", \n",
    "        sk_metric.classification_report(y_test, y_pred_lr, \n",
    "                                        target_names=targs, zero_division=0)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\"Liblinear failed to converge, increase the number of iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:16.500005 (hr:mn:sc)\n",
      "\n",
      " SVM Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.81      0.83      0.82      4531\n",
      " LOS <= mean       0.72      0.69      0.71      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.76      0.76      0.76      7404\n",
      "weighted avg       0.77      0.78      0.77      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_params = {'max_iter': 10**4}\n",
    "\n",
    "# Train Model\n",
    "start_time = check_time()\n",
    "svm_model = LinearSVC(**svm_params)\n",
    "svm_model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"SVM Prediction Scores:\", \"\\n\", \n",
    "        sk_metric.classification_report(y_test, y_pred_svm,\n",
    "                                        target_names=targs, zero_division=0) \n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:00.367544 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.73      0.91      0.81      4531\n",
      " LOS <= mean       0.76      0.47      0.58      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.74      0.69      0.69      7404\n",
      "weighted avg       0.74      0.74      0.72      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {'objective': 'binary', 'metric': 'auc', \n",
    "              'learning_rate': 0.03, 'num_leaves': 10,\n",
    "              'max_depth': 3}\n",
    "\n",
    "start_time = check_time()\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "lgb_model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "        sk_metric.classification_report(y_test, y_pred_lgb, target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:01:53.662104 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.79      0.88      0.83      4531\n",
      " LOS <= mean       0.77      0.63      0.70      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.78      0.76      0.76      7404\n",
      "weighted avg       0.78      0.78      0.78      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'colsample_bytree': 1.0, 'gamma': 2, \n",
    "              'learning_rate': 0.05, 'max_depth': 5, \n",
    "              'min_child_weight': 1,  'n_estimators': 600, \n",
    "              'subsample': 0.6\n",
    "             }\n",
    "\n",
    "# Train Model\n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "start_time = check_time()\n",
    "xgb_model.fit(X_train, y_train.iloc[:, 0])\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "        sk_metric.classification_report(y_test, y_pred_xgb, target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Part 2.2 - AIF360 Fairness-Aware  (In-Process) Models <a class = \"anchor\" id = \"part2.2\"></a>\n",
    "\n",
    "Reference: [AIF360 Inprocessing Algorithms](https://aif360.readthedocs.io/en/latest/modules/algorithms.html#module-aif360.algorithms.inprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "As noted [above](#custom_aif), the fairness-mitigating algorithms available in AIF360 require use of the library's custom data object. In the cells that follow we will attach our split data to one of those objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aif360.datasets as aifdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE</th>\n",
       "      <th>ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE</th>\n",
       "      <th>ETHNICITY_ASIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - ASIAN INDIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CAMBODIAN</th>\n",
       "      <th>ETHNICITY_ASIAN - CHINESE</th>\n",
       "      <th>ETHNICITY_ASIAN - FILIPINO</th>\n",
       "      <th>ETHNICITY_ASIAN - JAPANESE</th>\n",
       "      <th>...</th>\n",
       "      <th>PROCEDURE_CCS_222</th>\n",
       "      <th>PROCEDURE_CCS_223</th>\n",
       "      <th>PROCEDURE_CCS_224</th>\n",
       "      <th>PROCEDURE_CCS_225</th>\n",
       "      <th>PROCEDURE_CCS_226</th>\n",
       "      <th>PROCEDURE_CCS_227</th>\n",
       "      <th>PROCEDURE_CCS_228</th>\n",
       "      <th>PROCEDURE_CCS_229</th>\n",
       "      <th>PROCEDURE_CCS_231</th>\n",
       "      <th>long_los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  GENDER_M  ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE  \\\n",
       "0  80.0         1                                        0   \n",
       "1  80.0         1                                        0   \n",
       "2  80.0         0                                        0   \n",
       "3  65.0         0                                        0   \n",
       "4  75.0         1                                        0   \n",
       "\n",
       "   ETHNICITY_AMERICAN INDIAN/ALASKA NATIVE FEDERALLY RECOGNIZED TRIBE  \\\n",
       "0                                                  0                    \n",
       "1                                                  0                    \n",
       "2                                                  0                    \n",
       "3                                                  0                    \n",
       "4                                                  0                    \n",
       "\n",
       "   ETHNICITY_ASIAN  ETHNICITY_ASIAN - ASIAN INDIAN  \\\n",
       "0                0                               0   \n",
       "1                0                               0   \n",
       "2                0                               0   \n",
       "3                0                               0   \n",
       "4                0                               0   \n",
       "\n",
       "   ETHNICITY_ASIAN - CAMBODIAN  ETHNICITY_ASIAN - CHINESE  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "\n",
       "   ETHNICITY_ASIAN - FILIPINO  ETHNICITY_ASIAN - JAPANESE  ...  \\\n",
       "0                           0                           0  ...   \n",
       "1                           0                           0  ...   \n",
       "2                           0                           0  ...   \n",
       "3                           0                           0  ...   \n",
       "4                           0                           0  ...   \n",
       "\n",
       "   PROCEDURE_CCS_222  PROCEDURE_CCS_223  PROCEDURE_CCS_224  PROCEDURE_CCS_225  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  1                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   PROCEDURE_CCS_226  PROCEDURE_CCS_227  PROCEDURE_CCS_228  PROCEDURE_CCS_229  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   PROCEDURE_CCS_231  long_los  \n",
       "0                  0         0  \n",
       "1                  0         0  \n",
       "2                  0         1  \n",
       "3                  1         0  \n",
       "4                  0         1  \n",
       "\n",
       "[5 rows x 649 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "df = pd.concat([test_data, train_data], ignore_index=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aif_data = pd.concat([X, y], axis=1)\n",
    "los_dataset = aifdata.StandardDataset(df=aif_data, \n",
    "                                      label_name='long_los',\n",
    "                                      favorable_classes=[1],\n",
    "                                      instance_weights_name=None,\n",
    "                                      categorical_features=['AGE'],\n",
    "                                      protected_attribute_names=['LANGUAGE_ENGL'],       \n",
    "                                      privileged_classes=[[1]],                   \n",
    "                                      custom_preprocessing=None\n",
    "                                      )\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GerryFair Classifier\n",
    "\n",
    "Theoretically a predictor can be set, but valid argument could not be found during testing. Per the documentation: \"predictor: Hypothesis class for the Learner. Supports LR, SVM, KR, Trees\"\n",
    "\n",
    "Reference: [Kearns, Neel, Roth, Wu, 2018](https://arxiv.org/abs/1711.05144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import GerryFairClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 2, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 3, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 4, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "iteration: 5, error: 0.20986003387715074, fairness violation: 0.0036408985147281703, violated group size: 0.1964428991709013\n",
      "Model finished in 0:00:17.519050 (hr:mn:sc)\n"
     ]
    }
   ],
   "source": [
    "gf_params = {'fairness_def': \"FN\", 'C': 100,\n",
    "             'printflag': True, 'gamma': 0.005,\n",
    "             'max_iters': 500, 'heatmapflag': False}\n",
    "\n",
    "start_time = check_time()\n",
    "aif_gf_model = GerryFairClassifier(**gf_params)\n",
    "aif_gf_model.fit(los_dataset, early_termination=True)\n",
    "yhat_aifgf = aif_gf_model.predict(los_dataset, threshold=False)\n",
    "print(\"Model finished in\", check_time(start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prejudice Remover Regularizer\n",
    "\n",
    "Reference: [Kamishima et al., 2012](https://rd.springer.com/chapter/10.1007/978-3-642-33486-3_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import prejudice_remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:01:32.119658 (hr:mn:sc)\n"
     ]
    }
   ],
   "source": [
    "pr_params = {'sensitive_attr': \"LANGUAGE_ENGL\"}\n",
    "\n",
    "start_time = check_time()\n",
    "aif_prr_model = prejudice_remover.PrejudiceRemover(**pr_params)\n",
    "aif_prr_model.fit(los_dataset)\n",
    "yhat_aif_prr = aif_prr_model.predict(los_dataset)\n",
    "print(\"Model finished in\", check_time(start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Debiasing\n",
    "\n",
    "Reference: [Zhang et al., 2018](https://arxiv.org/abs/1801.07593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import adversarial_debiasing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version Check: passed. Current adversarial debiasing method is likely to work with your version of tensorflow.\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import StrictVersion\n",
    "\n",
    "run_adb = False\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    if StrictVersion(tf.__version__) >= StrictVersion('2.0.0'):\n",
    "        print(f\"ALERT: Current adversarial debiasing method may not be compatible with your version of tensorflow ({tf.__version__}).\",\n",
    "            \"Skipping this model.\")\n",
    "    else:\n",
    "        run_adb = True\n",
    "        print(\"Tensorflow Version Check: passed. Current adversarial debiasing method is likely to work with your version of tensorflow.\")\n",
    "except BaseException as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:137: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:141: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:89: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:159: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:161: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:165: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From ~/anaconda3/envs/fairMLHealth/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690905\n",
      "epoch 1; iter: 0; batch classifier loss: 0.474774\n",
      "epoch 2; iter: 0; batch classifier loss: 0.323571\n",
      "epoch 3; iter: 0; batch classifier loss: 0.382452\n",
      "epoch 4; iter: 0; batch classifier loss: 0.340088\n",
      "epoch 5; iter: 0; batch classifier loss: 0.324173\n",
      "epoch 6; iter: 0; batch classifier loss: 0.351611\n",
      "epoch 7; iter: 0; batch classifier loss: 0.419504\n",
      "epoch 8; iter: 0; batch classifier loss: 0.354349\n",
      "epoch 9; iter: 0; batch classifier loss: 0.353683\n",
      "epoch 10; iter: 0; batch classifier loss: 0.274232\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270510\n",
      "epoch 12; iter: 0; batch classifier loss: 0.351197\n",
      "epoch 13; iter: 0; batch classifier loss: 0.225857\n",
      "epoch 14; iter: 0; batch classifier loss: 0.249521\n",
      "epoch 15; iter: 0; batch classifier loss: 0.215338\n",
      "epoch 16; iter: 0; batch classifier loss: 0.191442\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241673\n",
      "epoch 18; iter: 0; batch classifier loss: 0.164882\n",
      "epoch 19; iter: 0; batch classifier loss: 0.171875\n",
      "epoch 20; iter: 0; batch classifier loss: 0.148026\n",
      "epoch 21; iter: 0; batch classifier loss: 0.142515\n",
      "epoch 22; iter: 0; batch classifier loss: 0.158955\n",
      "epoch 23; iter: 0; batch classifier loss: 0.146046\n",
      "epoch 24; iter: 0; batch classifier loss: 0.164772\n",
      "epoch 25; iter: 0; batch classifier loss: 0.132646\n",
      "epoch 26; iter: 0; batch classifier loss: 0.106943\n",
      "epoch 27; iter: 0; batch classifier loss: 0.095543\n",
      "epoch 28; iter: 0; batch classifier loss: 0.129375\n",
      "epoch 29; iter: 0; batch classifier loss: 0.142134\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188730\n",
      "epoch 31; iter: 0; batch classifier loss: 0.135238\n",
      "epoch 32; iter: 0; batch classifier loss: 0.115853\n",
      "epoch 33; iter: 0; batch classifier loss: 0.098177\n",
      "epoch 34; iter: 0; batch classifier loss: 0.066817\n",
      "epoch 35; iter: 0; batch classifier loss: 0.115226\n",
      "epoch 36; iter: 0; batch classifier loss: 0.092963\n",
      "epoch 37; iter: 0; batch classifier loss: 0.075343\n",
      "epoch 38; iter: 0; batch classifier loss: 0.063262\n",
      "epoch 39; iter: 0; batch classifier loss: 0.075400\n",
      "epoch 40; iter: 0; batch classifier loss: 0.063648\n",
      "epoch 41; iter: 0; batch classifier loss: 0.098662\n",
      "epoch 42; iter: 0; batch classifier loss: 0.061155\n",
      "epoch 43; iter: 0; batch classifier loss: 0.095680\n",
      "epoch 44; iter: 0; batch classifier loss: 0.072593\n",
      "epoch 45; iter: 0; batch classifier loss: 0.064550\n",
      "epoch 46; iter: 0; batch classifier loss: 0.061240\n",
      "epoch 47; iter: 0; batch classifier loss: 0.065209\n",
      "epoch 48; iter: 0; batch classifier loss: 0.052027\n",
      "epoch 49; iter: 0; batch classifier loss: 0.051312\n",
      "Model finished in 0:00:17.977016 (hr:mn:sc)\n"
     ]
    }
   ],
   "source": [
    "if run_adb:\n",
    "    sess = tf.compat.v1.Session()\n",
    "\n",
    "    adb_params = {'privileged_groups': [{'LANGUAGE_ENGL': 1}],\n",
    "                  'unprivileged_groups': [{'LANGUAGE_ENGL': 0}],\n",
    "                  'scope_name': 'plain_classifier',\n",
    "                  'debias': False,\n",
    "                  'sess': sess}\n",
    "\n",
    "    start_time = check_time()\n",
    "    aif_adb_model = adversarial_debiasing.AdversarialDebiasing(**adb_params)\n",
    "    aif_adb_model.fit(los_dataset)\n",
    "    yhat_aifadb = aif_adb_model.predict(los_dataset)\n",
    "    print(\"Model finished in\", check_time(start_time))\n",
    "else:\n",
    "    aif_adb_model = None\n",
    "    yhat_aifadb = np.zeros(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other AIF360 Fairness-Aware Options that are Not Yet Working for Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import meta_fair_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_fair_classifier failed to converge in testing\n"
     ]
    }
   ],
   "source": [
    "mf_params = {'sensitive_attr': \"LANGUAGE_ENGL\"}\n",
    "aif_mfc_model = meta_fair_classifier.MetaFairClassifier(**mf_params)\n",
    "#aif_mfc_model.fit(los_dataset)\n",
    "#yhat_aifmfc = aif_mfc_model.predict(los_dataset)\n",
    "print(\"meta_fair_classifier failed to converge in testing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Part 2.3 - Fairlearn Fairness-Aware  (In-Process) Models <a class = \"anchor\" id = \"part2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import GridSearch, ExponentiatedGradient\n",
    "from fairlearn.reductions import EqualizedOdds, DemographicParity \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Fair GridSearch --\n",
    "\n",
    "Fairlearn's GridSearch is a wrapper that runs a constrained optimization using the Grid Search approach  on a binary classification or a regression model. It treats the prediction as a sequence of cost-sensitive classification problems, returning the solution with the smallest error (constrained by the metric of choice). This approach has been demonstrated to have minimal effect on model performance by some measures [[Agarwal *et al* (2018)]](#ref).\n",
    "\n",
    "This approach is applicable to sensitive attributes that are binary/Boolean only. It can be used for either binary classification or regression problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair GridSearch on LGBM - Constrained by Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 0:00:50.297170 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.73      0.91      0.81      4531\n",
      " LOS <= mean       0.76      0.47      0.58      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.74      0.69      0.69      7404\n",
      "weighted avg       0.74      0.74      0.72      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_lgb_model = GridSearch(lgb.LGBMClassifier(**lgb_params),\n",
    "                           constraints=EqualizedOdds(),\n",
    "                           grid_size=45)\n",
    "\n",
    "start_time = check_time()\n",
    "gs_lgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_lgb = gs_lgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_lgb, \n",
    "            target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair GridSearch  with XGBOOST - Constrained by Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Kernel Failure when running GridSearch on XGBOOST\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "# Train GridSearch\n",
    "gs_xgb_model = GridSearch(XGBClassifier(**xgb_params),\n",
    "                   constraints=EqualizedOdds(),\n",
    "                   grid_size=45)\n",
    "\n",
    "start_time = check_time()\n",
    "gs_xgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_xgb = gs_xgb_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_xgb,\n",
    "            target_names = targs)\n",
    "      )\n",
    "      \n",
    "'''\n",
    "print(\"Frequent Kernel Failure when running GridSearch on XGBOOST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair GridSearch on Random Forest - Constrained by Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 1:33:16.051485 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.77      0.90      0.83      4531\n",
      " LOS <= mean       0.78      0.57      0.66      2873\n",
      "\n",
      "    accuracy                           0.77      7404\n",
      "   macro avg       0.77      0.73      0.74      7404\n",
      "weighted avg       0.77      0.77      0.76      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_rfEO_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                              constraints=EqualizedOdds(),\n",
    "                              grid_size=45)\n",
    "\n",
    "start_time = check_time()\n",
    "gs_rfEO_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfEO = gs_rfEO_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_rfEO, \n",
    "            target_names=targs)\n",
    "      )\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair GridSearch on Random Forest - Constrained by Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model finished in 1:27:18.086637 (hr:mn:sc)\n",
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.75      0.89      0.81      4531\n",
      " LOS <= mean       0.76      0.52      0.62      2873\n",
      "\n",
      "    accuracy                           0.75      7404\n",
      "   macro avg       0.75      0.71      0.71      7404\n",
      "weighted avg       0.75      0.75      0.74      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train GridSearch\n",
    "gs_rfDP_model = GridSearch(RandomForestClassifier(**rf_params),\n",
    "                           constraints=DemographicParity(),\n",
    "                           grid_size=45)\n",
    "\n",
    "start_time = check_time()\n",
    "gs_rfDP_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_gs_rfDP = gs_rfDP_model.predict(X_test)\n",
    "print(\"Model finished in\", check_time(start_time))\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_gs_rfDP, \n",
    "            target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Fairlearn ExponentiatedGradient --\n",
    "\n",
    "Fairlearn's ExponentiatedGradient is a wrapper that runs a constrained optimization using the Exponentiated Gradient approach on a binary classification model. It treats the prediction as a sequence of cost-sensitive classification problems, returning the solution with the smallest error (constrained by the metric of choice). This approach has been demonstrated to have minimal effect on model performance by some measures. [Agarwal2018](#Agarwal2018)\n",
    "\n",
    "This approach is applicable to sensitive attributes that are either categorical or binary/Boolean. It can be used for classification problems only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for consistent results with Fairlearn's ExponentiatedGradient\n",
    "np.random.seed(36)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairlearn ExponentiatedGradient on Random Forest - Constrained by Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.73      0.90      0.81      4531\n",
      " LOS <= mean       0.76      0.47      0.58      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.74      0.69      0.69      7404\n",
      "weighted avg       0.74      0.74      0.72      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eg_lgb_model = ExponentiatedGradient(lgb.LGBMClassifier(**lgb_params), \n",
    "                                     constraints=DemographicParity())\n",
    "eg_lgb_model.fit(X_train, y_train, sensitive_features=X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_lgb = eg_lgb_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_eg_lgb,\n",
    "            target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairlearn ExponentiatedGradient on Random Forest - Constrained by Demographic Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.74      0.90      0.81      4531\n",
      " LOS <= mean       0.76      0.51      0.61      2873\n",
      "\n",
      "    accuracy                           0.74      7404\n",
      "   macro avg       0.75      0.70      0.71      7404\n",
      "weighted avg       0.75      0.74      0.73      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eg_rf_model = ExponentiatedGradient(RandomForestClassifier(**rf_params), \n",
    "                                    constraints=DemographicParity())\n",
    "eg_rf_model.fit(X_train, y_train, sensitive_features = X_train['LANGUAGE_ENGL'])\n",
    "y_pred_eg_rf = eg_rf_model.predict(X_test)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_eg_rf, \n",
    "            target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Part 2.4 - Other Methods <a class = \"anchor\" id = \"part2.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -- Fair Empirical Risk Minimization (Fair_ERM) --\n",
    "\n",
    "Reference: [Donini, M., Oneto, L., Ben-David, S., Shawe-Taylor, J. S., & Pontil, M. (2018). Empirical risk minimization under fairness constraints. In Advances in Neural Information Processing Systems (pp. 2791-2801)](https://papers.nips.cc/paper/7544-empirical-risk-minimization-under-fairness-constraints)\n",
    "\n",
    "Repo: https://github.com/jmikko/fair_ERM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear FERM\n",
    "\n",
    "Code taken from https://github.com/jmikko/fair_ERM/blob/master/linear_ferm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_FERM:\n",
    "    \"\"\" Fairness-Aware Classifier from https://github.com/jmikko/fair_ERM/blob/master/linear_ferm.py\n",
    "    \"\"\"\n",
    "    # The linear FERM algorithm\n",
    "    def __init__(self, dataset, model, sensible_feature):\n",
    "        self.dataset = dataset\n",
    "        self.values_of_sensible_feature = list(set(sensible_feature))\n",
    "        self.list_of_sensible_feature_train = sensible_feature\n",
    "        self.val0 = np.min(self.values_of_sensible_feature)\n",
    "        self.val1 = np.max(self.values_of_sensible_feature)\n",
    "        self.model = model\n",
    "        self.u = None\n",
    "        self.max_i = None\n",
    "\n",
    "    def new_representation(self, examples):\n",
    "        if self.u is None:\n",
    "            sys.exit('Model not trained yet!')\n",
    "            return 0\n",
    "\n",
    "        new_examples = np.array([ex - self.u * (ex[self.max_i] / self.u[self.max_i]) for ex in examples])\n",
    "        new_examples = np.delete(new_examples, self.max_i, 1)\n",
    "        return new_examples\n",
    "\n",
    "    def predict(self, examples):\n",
    "        new_examples = self.new_representation(examples)\n",
    "        prediction = self.model.predict(new_examples)\n",
    "        return prediction\n",
    "\n",
    "    def fit(self):\n",
    "        # Evaluation of the empirical averages among the groups\n",
    "        tmp = [ex for idx, ex in enumerate(self.dataset.data)\n",
    "               if self.dataset.target[idx] == 1 and self.list_of_sensible_feature_train[idx] == self.val1]\n",
    "        average_A_1 = np.mean(tmp, 0)\n",
    "        tmp = [ex for idx, ex in enumerate(self.dataset.data)\n",
    "               if self.dataset.target[idx] == 1 and self.list_of_sensible_feature_train[idx] == self.val0]\n",
    "        average_not_A_1 = np.mean(tmp, 0)\n",
    "\n",
    "        # Evaluation of the vector u (difference among the two averages)\n",
    "        self.u = -(average_A_1 - average_not_A_1)\n",
    "        self.max_i = np.argmax(self.u)\n",
    "\n",
    "        # Application of the new representation\n",
    "        newdata = np.array([ex - self.u * (ex[self.max_i] / self.u[self.max_i]) for ex in self.dataset.data])\n",
    "        newdata = np.delete(newdata, self.max_i, 1)\n",
    "        self.dataset = namedtuple('_', 'data, target')(newdata, self.dataset.target)\n",
    "\n",
    "        # Fitting the linear model by using the new data\n",
    "        if self.model:\n",
    "            self.model.fit(self.dataset.data, self.dataset.target)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.79      0.87      0.83      4531\n",
      " LOS <= mean       0.76      0.63      0.69      2873\n",
      "\n",
      "    accuracy                           0.78      7404\n",
      "   macro avg       0.77      0.75      0.76      7404\n",
      "weighted avg       0.78      0.78      0.77      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import copy\n",
    "\n",
    "\n",
    "train_dataset = namedtuple('_', 'data, target')(X_train.to_numpy(),    \n",
    "                              y_train.to_numpy())\n",
    "test_dataset = namedtuple('_', 'data, target')(X_test.to_numpy(),\n",
    "                              y_test.to_numpy())\n",
    "\n",
    "# predictor must be trained (or otherwise have attribute 'estimators_'); predictor may be altered by the fit process (TODO: check this)\n",
    "lr_predictor = copy.deepcopy(lr_model)\n",
    "ermL_lr_model = Linear_FERM(train_dataset, lr_predictor, X_train['LANGUAGE_ENGL'].to_numpy())\n",
    "ermL_lr_model.fit()\n",
    "y_pred_ermL_lr = ermL_lr_model.predict(test_dataset.data)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_ermL_lr,\n",
    "            target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Prediction Scores: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  LOS > mean       0.88      0.63      0.74      4531\n",
      " LOS <= mean       0.60      0.86      0.71      2873\n",
      "\n",
      "    accuracy                           0.72      7404\n",
      "   macro avg       0.74      0.75      0.72      7404\n",
      "weighted avg       0.77      0.72      0.73      7404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# predictor must be trained (or otherwise have attribute 'estimators_'); predictor may be altered by the fit process (TODO: check this)\n",
    "svm_predictor = copy.deepcopy(svm_model)\n",
    "ermL_svm_model = Linear_FERM(train_dataset, svm_predictor, X_train['LANGUAGE_ENGL'].to_numpy())\n",
    "ermL_svm_model.fit()\n",
    "y_pred_ermL_svm = ermL_svm_model.predict(test_dataset.data)\n",
    "\n",
    "# display performance \n",
    "print(\"\\n\", \"Prediction Scores:\", \"\\n\", \n",
    "      sk_metric.classification_report(y_test, y_pred_ermL_svm,\n",
    "            target_names=targs)\n",
    "      )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 3 - Comparing Models <a class = \"anchor\" id = \"part3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll generate a set of dictionaries that will allow us to view our models in meaningful groups. Note that the Naive Bayes model and the Decision Tree model are not considered in this section due to relatively poor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37716    1\n",
       "33259    1\n",
       "Name: LANGUAGE_ENGL, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pointer for the sensitive attribute series (called often)\n",
    "prtc_attrs = X_test['LANGUAGE_ENGL']\n",
    "prtc_attrs.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the FairMLHealth Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIF360 Models\n",
    "*AIF360 was dropped from consideration due to the challenge of logistics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aif_gf_model</th>\n",
       "      <th>aif_prr_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <td>1.212619</td>\n",
       "      <td>1.208887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.057558</td>\n",
       "      <td>0.062899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.030190</td>\n",
       "      <td>0.034180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.037543</td>\n",
       "      <td>0.043702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy Difference</th>\n",
       "      <td>0.757601</td>\n",
       "      <td>0.773845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Between-Group Coefficient of Variation</th>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.004872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theil Index</th>\n",
       "      <td>0.186016</td>\n",
       "      <td>0.165591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        aif_gf_model  aif_prr_model\n",
       "Disparate Impact Ratio                      1.212619       1.208887\n",
       "Statistical Parity Difference               0.057558       0.062899\n",
       "Average Odds Difference                     0.030190       0.034180\n",
       "Equal Opportunity Difference                0.037543       0.043702\n",
       "Balanced Accuracy Difference                0.757601       0.773845\n",
       "Between-Group Coefficient of Variation      0.000908       0.004872\n",
       "Theil Index                                 0.186016       0.165591"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aif_models = {'aif_gf_model': aif_gf_model, \n",
    "              'aif_prr_model': aif_prr_model\n",
    "              # 'aif_adb_model': aif_adb_model ## not working (bug)\n",
    "              }\n",
    "\n",
    "aif_dataset_measures(dataset=los_dataset, models=aif_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models\n",
    "*Models that could be mitigated by Fair ERM and their mitigated counterparts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure predicting probabilities for ermL_lr_model. Related metrics will be skipped.\n",
      "Failure predicting probabilities for svm_model. Related metrics will be skipped.\n",
      "Failure predicting probabilities for ermL_svm_model. Related metrics will be skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_4ce2f980_091f_11eb_9198_f0189849bf4brow4_col0,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow4_col1,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow4_col2,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow4_col3,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow5_col0,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow5_col1,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow5_col2,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow5_col3,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow8_col0,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow8_col1,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow8_col2,#T_4ce2f980_091f_11eb_9198_f0189849bf4brow8_col3{\n",
       "            color: magenta;\n",
       "        }</style><table id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4b\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >lr_model</th>        <th class=\"col_heading level0 col1\" >ermL_lr_model</th>        <th class=\"col_heading level0 col2\" >svm_model</th>        <th class=\"col_heading level0 col3\" >ermL_svm_model</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel0_row0\" class=\"row_heading level0 row0\" rowspan=11>Group Fairness</th>\n",
       "                        <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row0\" class=\"row_heading level1 row0\" >AUC Difference</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow0_col0\" class=\"data row0 col0\" >-0.009300</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row1\" class=\"row_heading level1 row1\" >Average Odds Difference</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow1_col0\" class=\"data row1 col0\" >0.034400</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow1_col1\" class=\"data row1 col1\" >0.012100</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow1_col2\" class=\"data row1 col2\" >0.011000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow1_col3\" class=\"data row1 col3\" >0.029400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row2\" class=\"row_heading level1 row2\" >Balanced Accuracy Difference</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow2_col0\" class=\"data row2 col0\" >-0.004600</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow2_col1\" class=\"data row2 col1\" >-0.010200</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow2_col2\" class=\"data row2 col2\" >-0.008700</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow2_col3\" class=\"data row2 col3\" >-0.012500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row3\" class=\"row_heading level1 row3\" >Demographic Parity Difference</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow3_col0\" class=\"data row3 col0\" >0.064000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow3_col1\" class=\"data row3 col1\" >0.043100</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow3_col2\" class=\"data row3 col2\" >0.038700</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow3_col3\" class=\"data row3 col3\" >0.060700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row4\" class=\"row_heading level1 row4\" >Demographic Parity Ratio</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow4_col0\" class=\"data row4 col0\" >0.821500</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow4_col1\" class=\"data row4 col1\" >0.875500</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow4_col2\" class=\"data row4 col2\" >0.851800</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow4_col3\" class=\"data row4 col3\" >0.897800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row5\" class=\"row_heading level1 row5\" >Disparate Impact Ratio</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow5_col0\" class=\"data row5 col0\" >1.217300</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow5_col1\" class=\"data row5 col1\" >1.142200</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow5_col2\" class=\"data row5 col2\" >1.174000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow5_col3\" class=\"data row5 col3\" >1.113900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row6\" class=\"row_heading level1 row6\" >Equal Opportunity Difference</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow6_col0\" class=\"data row6 col0\" >0.029800</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow6_col1\" class=\"data row6 col1\" >0.002000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow6_col2\" class=\"data row6 col2\" >0.002300</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow6_col3\" class=\"data row6 col3\" >0.016900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row7\" class=\"row_heading level1 row7\" >Equalized Odds Difference</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow7_col0\" class=\"data row7 col0\" >0.039000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow7_col1\" class=\"data row7 col1\" >0.022300</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow7_col2\" class=\"data row7 col2\" >0.019700</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow7_col3\" class=\"data row7 col3\" >0.042000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row8\" class=\"row_heading level1 row8\" >Equalized Odds Ratio</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow8_col0\" class=\"data row8 col0\" >0.744000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow8_col1\" class=\"data row8 col1\" >0.841900</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow8_col2\" class=\"data row8 col2\" >0.744100</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow8_col3\" class=\"data row8 col3\" >0.892700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row9\" class=\"row_heading level1 row9\" >Positive Predictive Parity Difference</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow9_col0\" class=\"data row9 col0\" >-0.001100</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow9_col1\" class=\"data row9 col1\" >0.013500</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow9_col2\" class=\"data row9 col2\" >-0.006800</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow9_col3\" class=\"data row9 col3\" >0.035600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row10\" class=\"row_heading level1 row10\" >Statistical Parity Difference</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow10_col0\" class=\"data row10 col0\" >0.064000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow10_col1\" class=\"data row10 col1\" >0.043100</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow10_col2\" class=\"data row10 col2\" >0.038700</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow10_col3\" class=\"data row10 col3\" >0.060700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel0_row11\" class=\"row_heading level0 row11\" rowspan=2>Individual Fairness</th>\n",
       "                        <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row11\" class=\"row_heading level1 row11\" >Between-Group Generalized Entropy Error</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow11_col1\" class=\"data row11 col1\" >0.000000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow11_col2\" class=\"data row11 col2\" >0.000100</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow11_col3\" class=\"data row11 col3\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row12\" class=\"row_heading level1 row12\" >Consistency Score</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow12_col0\" class=\"data row12 col0\" >0.773000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow12_col1\" class=\"data row12 col1\" >0.774400</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow12_col2\" class=\"data row12 col2\" >0.825100</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow12_col3\" class=\"data row12 col3\" >0.675600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel0_row13\" class=\"row_heading level0 row13\" rowspan=4>Model Performance **</th>\n",
       "                        <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row13\" class=\"row_heading level1 row13\" >Accuracy</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow13_col0\" class=\"data row13 col0\" >0.776300</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow13_col1\" class=\"data row13 col1\" >0.777100</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow13_col2\" class=\"data row13 col2\" >0.771300</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow13_col3\" class=\"data row13 col3\" >0.722600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row14\" class=\"row_heading level1 row14\" >F1-Score</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow14_col0\" class=\"data row14 col0\" >0.685800</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow14_col1\" class=\"data row14 col1\" >0.686300</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow14_col2\" class=\"data row14 col2\" >0.635800</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow14_col3\" class=\"data row14 col3\" >0.707400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row15\" class=\"row_heading level1 row15\" >Precision</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow15_col0\" class=\"data row15 col0\" >0.753900</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow15_col1\" class=\"data row15 col1\" >0.756200</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow15_col2\" class=\"data row15 col2\" >0.832200</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow15_col3\" class=\"data row15 col3\" >0.598700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4blevel1_row16\" class=\"row_heading level1 row16\" >Recall</th>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow16_col0\" class=\"data row16 col0\" >0.629000</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow16_col1\" class=\"data row16 col1\" >0.628300</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow16_col2\" class=\"data row16 col2\" >0.514400</td>\n",
       "                        <td id=\"T_4ce2f980_091f_11eb_9198_f0189849bf4brow16_col3\" class=\"data row16 col3\" >0.864300</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_models = {'lr_model': lr_model, 'ermL_lr_model': ermL_lr_model,\n",
    "                 'svm_model': svm_model, 'ermL_svm_model': ermL_svm_model}\n",
    "                 \n",
    "lin_comp = report.compare_measures(X_test, y_test, prtc_attrs, linear_models)\n",
    "\n",
    "measure.flag(lin_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Methods\n",
    "*Gradient boosted models that were mitigated by Fair Grid Search, and their mitigated counterparts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_6ea2b234_1871_11eb_ab27_f0189849bf4brow1_col0,#T_6ea2b234_1871_11eb_ab27_f0189849bf4brow1_col1,#T_6ea2b234_1871_11eb_ab27_f0189849bf4brow1_col2,#T_6ea2b234_1871_11eb_ab27_f0189849bf4brow7_col0,#T_6ea2b234_1871_11eb_ab27_f0189849bf4brow7_col1,#T_6ea2b234_1871_11eb_ab27_f0189849bf4brow7_col2{\n",
       "            color: magenta;\n",
       "        }</style><table id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4b\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >xgboost_model</th>        <th class=\"col_heading level0 col1\" >lgbm_model</th>        <th class=\"col_heading level0 col2\" >gs_lgbm_model</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel0_row0\" class=\"row_heading level0 row0\" rowspan=11>Group Fairness</th>\n",
       "                        <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row0\" class=\"row_heading level1 row0\" >Statistical Parity Difference</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow0_col0\" class=\"data row0 col0\" >0.062200</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow0_col1\" class=\"data row0 col1\" >0.031600</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow0_col2\" class=\"data row0 col2\" >0.031600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row1\" class=\"row_heading level1 row1\" >Disparate Impact Ratio</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow1_col0\" class=\"data row1 col0\" >1.213400</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow1_col1\" class=\"data row1 col1\" >1.139200</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow1_col2\" class=\"data row1 col2\" >1.139200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row2\" class=\"row_heading level1 row2\" >Demographic Parity Difference</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow2_col0\" class=\"data row2 col0\" >0.062200</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow2_col1\" class=\"data row2 col1\" >0.031600</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow2_col2\" class=\"data row2 col2\" >0.031600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row3\" class=\"row_heading level1 row3\" >Demographic Parity Ratio</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow3_col0\" class=\"data row3 col0\" >0.824200</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow3_col1\" class=\"data row3 col1\" >0.877800</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow3_col2\" class=\"data row3 col2\" >0.877800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row4\" class=\"row_heading level1 row4\" >Average Odds Difference</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow4_col0\" class=\"data row4 col0\" >0.033700</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow4_col1\" class=\"data row4 col1\" >0.010600</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow4_col2\" class=\"data row4 col2\" >0.010600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row5\" class=\"row_heading level1 row5\" >Equal Opportunity Difference</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow5_col0\" class=\"data row5 col0\" >0.038400</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow5_col1\" class=\"data row5 col1\" >0.013800</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow5_col2\" class=\"data row5 col2\" >0.013800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row6\" class=\"row_heading level1 row6\" >Equalized Odds Difference</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow6_col0\" class=\"data row6 col0\" >0.038400</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow6_col1\" class=\"data row6 col1\" >0.013800</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow6_col2\" class=\"data row6 col2\" >0.013800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row7\" class=\"row_heading level1 row7\" >Equalized Odds Ratio</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow7_col0\" class=\"data row7 col0\" >0.788200</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow7_col1\" class=\"data row7 col1\" >0.926100</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow7_col2\" class=\"data row7 col2\" >0.926100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row8\" class=\"row_heading level1 row8\" >Positive Predictive Parity Difference</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow8_col0\" class=\"data row8 col0\" >0.011500</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow8_col1\" class=\"data row8 col1\" >0.035600</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow8_col2\" class=\"data row8 col2\" >0.035600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row9\" class=\"row_heading level1 row9\" >Balanced Accuracy Difference</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow9_col0\" class=\"data row9 col0\" >0.004700</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow9_col1\" class=\"data row9 col1\" >0.003300</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow9_col2\" class=\"data row9 col2\" >0.003300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row10\" class=\"row_heading level1 row10\" >AUC Difference</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow10_col0\" class=\"data row10 col0\" >-0.000500</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow10_col1\" class=\"data row10 col1\" >0.004500</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow10_col2\" class=\"data row10 col2\" >0.004500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel0_row11\" class=\"row_heading level0 row11\" rowspan=2>Individual Fairness</th>\n",
       "                        <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row11\" class=\"row_heading level1 row11\" >Consistency Score</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow11_col0\" class=\"data row11 col0\" >0.781600</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow11_col1\" class=\"data row11 col1\" >0.846200</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow11_col2\" class=\"data row11 col2\" >0.846200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row12\" class=\"row_heading level1 row12\" >Between-Group Generalized Entropy Error</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow12_col0\" class=\"data row12 col0\" >0.000000</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow12_col1\" class=\"data row12 col1\" >0.000100</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow12_col2\" class=\"data row12 col2\" >0.000100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel0_row13\" class=\"row_heading level0 row13\" rowspan=4>Model Performance **</th>\n",
       "                        <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row13\" class=\"row_heading level1 row13\" >Precision</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow13_col0\" class=\"data row13 col0\" >0.770200</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow13_col1\" class=\"data row13 col1\" >0.759100</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow13_col2\" class=\"data row13 col2\" >0.759100</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row14\" class=\"row_heading level1 row14\" >Recall</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow14_col0\" class=\"data row14 col0\" >0.634500</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow14_col1\" class=\"data row14 col1\" >0.471600</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow14_col2\" class=\"data row14 col2\" >0.471600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row15\" class=\"row_heading level1 row15\" >F1-Score</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow15_col0\" class=\"data row15 col0\" >0.695800</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow15_col1\" class=\"data row15 col1\" >0.581800</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow15_col2\" class=\"data row15 col2\" >0.581800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4blevel1_row16\" class=\"row_heading level1 row16\" >Accuracy</th>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow16_col0\" class=\"data row16 col0\" >0.784700</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow16_col1\" class=\"data row16 col1\" >0.736900</td>\n",
       "                        <td id=\"T_6ea2b234_1871_11eb_ab27_f0189849bf4brow16_col2\" class=\"data row16 col2\" >0.736900</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: fix gs_xgb_model - find reason for kernel interrupt\n",
    "boosted_models = {'xgboost_model': xgb_model, #'gs_xgb_model': gs_xgb_model,\n",
    "                  'lgbm_model': lgb_model, 'gs_lgbm_model': gs_lgb_model}\n",
    "\n",
    "boost_comp = report.compare_measures(X_test, y_test, prtc_attrs, boosted_models) \n",
    "\n",
    "measure.flag(boost_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Models\n",
    "*Random Forest model and its mitigated counterparts*\n",
    "\n",
    "Random forest has been selected as the method of choice for the example for two reasons: it has competitive performance relative to the other models under examination, and both the baseline model and its mitigated counterparts can be processed relatively quickly. It also happens to demonstrate greater change in measures among the different versions, however this was only a minor consideration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure predicting probabilities for eg_rf_model. Related metrics will be skipped.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_4761ba36_0920_11eb_9198_f0189849bf4brow4_col0,#T_4761ba36_0920_11eb_9198_f0189849bf4brow4_col1,#T_4761ba36_0920_11eb_9198_f0189849bf4brow4_col2,#T_4761ba36_0920_11eb_9198_f0189849bf4brow4_col3,#T_4761ba36_0920_11eb_9198_f0189849bf4brow8_col0,#T_4761ba36_0920_11eb_9198_f0189849bf4brow8_col1,#T_4761ba36_0920_11eb_9198_f0189849bf4brow8_col2,#T_4761ba36_0920_11eb_9198_f0189849bf4brow8_col3{\n",
       "            color: magenta;\n",
       "        }</style><table id=\"T_4761ba36_0920_11eb_9198_f0189849bf4b\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >rf_model</th>        <th class=\"col_heading level0 col1\" >gs_rfEO_model</th>        <th class=\"col_heading level0 col2\" >gs_rfDP_model</th>        <th class=\"col_heading level0 col3\" >eg_rf_model</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel0_row0\" class=\"row_heading level0 row0\" rowspan=11>Group Fairness</th>\n",
       "                        <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row0\" class=\"row_heading level1 row0\" >AUC Difference</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow0_col0\" class=\"data row0 col0\" >0.002800</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow0_col1\" class=\"data row0 col1\" >0.004100</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow0_col2\" class=\"data row0 col2\" >0.006900</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row1\" class=\"row_heading level1 row1\" >Average Odds Difference</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow1_col0\" class=\"data row1 col0\" >0.021600</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow1_col1\" class=\"data row1 col1\" >0.021600</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow1_col2\" class=\"data row1 col2\" >-0.153600</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow1_col3\" class=\"data row1 col3\" >-0.179500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row2\" class=\"row_heading level1 row2\" >Balanced Accuracy Difference</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow2_col0\" class=\"data row2 col0\" >0.003200</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow2_col1\" class=\"data row2 col1\" >-0.000300</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow2_col2\" class=\"data row2 col2\" >-0.058400</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow2_col3\" class=\"data row2 col3\" >-0.071400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row3\" class=\"row_heading level1 row3\" >Demographic Parity Difference</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow3_col0\" class=\"data row3 col0\" >0.047900</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow3_col1\" class=\"data row3 col1\" >0.048700</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow3_col2\" class=\"data row3 col2\" >0.116700</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow3_col3\" class=\"data row3 col3\" >0.140600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row4\" class=\"row_heading level1 row4\" >Demographic Parity Ratio</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow4_col0\" class=\"data row4 col0\" >0.845800</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow4_col1\" class=\"data row4 col1\" >0.843400</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow4_col2\" class=\"data row4 col2\" >0.635200</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow4_col3\" class=\"data row4 col3\" >0.563800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row5\" class=\"row_heading level1 row5\" >Disparate Impact Ratio</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow5_col0\" class=\"data row5 col0\" >1.182400</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow5_col1\" class=\"data row5 col1\" >1.185700</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow5_col2\" class=\"data row5 col2\" >0.635200</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow5_col3\" class=\"data row5 col3\" >0.563800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row6\" class=\"row_heading level1 row6\" >Equal Opportunity Difference</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow6_col0\" class=\"data row6 col0\" >0.024800</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow6_col1\" class=\"data row6 col1\" >0.021300</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow6_col2\" class=\"data row6 col2\" >-0.212000</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow6_col3\" class=\"data row6 col3\" >-0.250900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row7\" class=\"row_heading level1 row7\" >Equalized Odds Difference</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow7_col0\" class=\"data row7 col0\" >0.024800</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow7_col1\" class=\"data row7 col1\" >0.021900</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow7_col2\" class=\"data row7 col2\" >0.212000</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow7_col3\" class=\"data row7 col3\" >0.250900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row8\" class=\"row_heading level1 row8\" >Equalized Odds Ratio</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow8_col0\" class=\"data row8 col0\" >0.836800</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow8_col1\" class=\"data row8 col1\" >0.808300</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow8_col2\" class=\"data row8 col2\" >0.355000</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow8_col3\" class=\"data row8 col3\" >0.280200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row9\" class=\"row_heading level1 row9\" >Positive Predictive Parity Difference</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow9_col0\" class=\"data row9 col0\" >0.018400</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow9_col1\" class=\"data row9 col1\" >0.011500</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow9_col2\" class=\"data row9 col2\" >0.144600</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow9_col3\" class=\"data row9 col3\" >0.162900</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row10\" class=\"row_heading level1 row10\" >Statistical Parity Difference</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow10_col0\" class=\"data row10 col0\" >0.047900</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow10_col1\" class=\"data row10 col1\" >0.048700</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow10_col2\" class=\"data row10 col2\" >-0.116700</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow10_col3\" class=\"data row10 col3\" >-0.140600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel0_row11\" class=\"row_heading level0 row11\" rowspan=2>Individual Fairness</th>\n",
       "                        <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row11\" class=\"row_heading level1 row11\" >Between-Group Generalized Entropy Error</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow11_col0\" class=\"data row11 col0\" >0.000000</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow11_col1\" class=\"data row11 col1\" >0.000000</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow11_col2\" class=\"data row11 col2\" >0.004900</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow11_col3\" class=\"data row11 col3\" >0.006400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row12\" class=\"row_heading level1 row12\" >Consistency Score</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow12_col0\" class=\"data row12 col0\" >0.810500</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow12_col1\" class=\"data row12 col1\" >0.810600</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow12_col2\" class=\"data row12 col2\" >0.813600</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow12_col3\" class=\"data row12 col3\" >0.816200</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel0_row13\" class=\"row_heading level0 row13\" rowspan=4>Model Performance **</th>\n",
       "                        <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row13\" class=\"row_heading level1 row13\" >Accuracy</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow13_col0\" class=\"data row13 col0\" >0.771500</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow13_col1\" class=\"data row13 col1\" >0.771300</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow13_col2\" class=\"data row13 col2\" >0.748500</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow13_col3\" class=\"data row13 col3\" >0.743700</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row14\" class=\"row_heading level1 row14\" >F1-Score</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow14_col0\" class=\"data row14 col0\" >0.660100</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow14_col1\" class=\"data row14 col1\" >0.659800</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow14_col2\" class=\"data row14 col2\" >0.616100</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow14_col3\" class=\"data row14 col3\" >0.603600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row15\" class=\"row_heading level1 row15\" >Precision</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow15_col0\" class=\"data row15 col0\" >0.780500</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow15_col1\" class=\"data row15 col1\" >0.780400</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow15_col2\" class=\"data row15 col2\" >0.755700</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow15_col3\" class=\"data row15 col3\" >0.754600</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_4761ba36_0920_11eb_9198_f0189849bf4blevel1_row16\" class=\"row_heading level1 row16\" >Recall</th>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow16_col0\" class=\"data row16 col0\" >0.571900</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow16_col1\" class=\"data row16 col1\" >0.571500</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow16_col2\" class=\"data row16 col2\" >0.520000</td>\n",
       "                        <td id=\"T_4761ba36_0920_11eb_9198_f0189849bf4brow16_col3\" class=\"data row16 col3\" >0.503000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_models = {'rf_model': rf_model, 'gs_rfEO_model': gs_rfEO_model,\n",
    "            'gs_rfDP_model': gs_rfDP_model, 'eg_rf_model': eg_rf_model}\n",
    "\n",
    "rf_comp = report.compare_measures(X_test, y_test, prtc_attrs, rf_models)\n",
    "\n",
    "measure.flag(rf_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the Fairlearn Dashboard\n",
    "\n",
    "Fairlearn comes with its own model comparison dashboard to allow visual comparison between models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f86df8b5af4479b6bde3f949c5e82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FairlearnWidget(value={'true_y': [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<fairlearn.widget._fairlearn_dashboard.FairlearnDashboard at 0x7f87e37300d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairlearn.widget import FairlearnDashboard\n",
    "\n",
    "FairlearnDashboard(sensitive_features=prtc_attrs.to_list(), \n",
    "                   sensitive_feature_names=['LANGUAGE_ENGL'],\n",
    "                   y_true=y_test.iloc[:, 0].to_list(),\n",
    "                   y_pred={k:model.predict(X_test) for k,model in rf_models.items()}\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Part 4 - Save Results <a class = \"anchor\" id = \"part4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change save_data to True to save notebook results to output_file\n",
    "output_file = os.path.expanduser(\"~/data/fairMLHealth/supplemental_modelData\")\n",
    "save_data = False \n",
    "\n",
    "if save_data:\n",
    "        output_models = rf_models\n",
    "        packet = report.FairCompare(test_data=X_test, target_data=y_test,\n",
    "                                  models=models, train_data=train_data)\n",
    "        if not os.path.exists(os.path.dirname(output_file)):\n",
    "                os.makedirs(output_file)\n",
    "        dump(packet, output_file)\n",
    "else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a id=\"ref\"></a>\n",
    "Agarwal, A., Beygelzimer, A., Dudík, M., Langford, J., & Wallach, H. (2018). A reductions approach to fair classification. [arXiv preprint arXiv:1803.02453](https://arxiv.org/pdf/1803.02453.pdf).\n",
    "\n",
    "Agarwal, A., Dudík, M., & Wu, Z. S. (2019). Fair regression: Quantitative definitions and reduction-based algorithms. arXiv preprint [arXiv:1905.1284](https://arxiv.org/pdf/1905.12843.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ef970c290f551a7347bf6c12f2572994a9433a2b44c4a024b422a0dd0c2a867"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
